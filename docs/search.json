[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AKR Map Visualisation from Wind Satellite Data",
    "section": "",
    "text": "# 1. Importing Libraries\nimport sys\nfrom pathlib import Path\n\n# 2. Setting project paths\nproject_root = Path.cwd()\nsys.path.append(str(project_root))\n\n# Define standard data subdirectories for easy access later\nRAW_DATA_DIR = project_root / \"data\" / \"raw\"\nPROCESSED_DATA_DIR = project_root / \"data\" / \"processed\"\nASSETS_DIR = project_root / \"assets\" / \"3D_Objects\"\n\n\n\n\n\n\n\n# 1. Importing functions from Package_Name\nfrom scripts.wind_data_reading import (\n    exploding_saving_wind_data,\n    load_apply_schema_wind_csv,\n)\n\n# 2. Loading and applying data type schema to wind data from CSV\nwind_data = load_apply_schema_wind_csv(\n    f\"{RAW_DATA_DIR}/fogg_akr_burst_list_1995_2004.csv\",\n)\n\n\n\n\n\n# 1. Exploding nested data and filtering NaNs\nwind_data_processed = exploding_saving_wind_data(wind_data)\n\nData cleaned. Remaining rows: 245918\n\n\n\n\n\n\n# 1. Processed data name\nprocessed_data_base_name = \"01_processed_wind_data_fogg_akr_burst_list_1995_2004\"\n\n# 2. Saving in parquet format (memory efficient)\nwind_data_processed.to_parquet(\n    f\"{PROCESSED_DATA_DIR}/{processed_data_base_name}.parquet\",\n    engine=\"pyarrow\",\n    index=False,\n)\n\n# 3. Saving in json format\nwind_data_processed.to_json(\n    f\"{PROCESSED_DATA_DIR}/{processed_data_base_name}.json\",\n    index=False,\n)\n\nprint(f\"Data successfully saved to: {PROCESSED_DATA_DIR}\")\n\nData successfully saved to: F:\\gitrepos\\AKR_3D_map\\data\\processed\n\n\n\n\n\n\n\n# 1. Importing libraries\nimport pandas as pd\n\n# 2. Importing parquet file\nwind_data = pd.read_parquet(\n    f\"{project_root}/data/processed/01_processed_wind_data_fogg_akr_burst_list_1995_2004.parquet\",\n)\n\n# 3. Descriptory analysis\nprint(\"__________ Data type of columns __________\")\nprint(wind_data.dtypes)\nprint(\"\\n\")\nprint(\"__________ Data summary __________\")\nprint((wind_data.groupby(\"original_burst_id\").size().describe()))\n\n__________ Data type of columns __________\noriginal_burst_id             int64\nstime                datetime64[ns]\netime                datetime64[ns]\nburst_timestamp      datetime64[ns]\nmin_f_bound                 float64\nmax_f_bound                 float64\nLT_gse                      float64\nradius                      float64\nlat_gse                     float64\nlon_gse                     float64\nx_gse                       float64\ny_gse                       float64\nz_gse                       float64\ndtype: object\n\n\n__________ Data summary __________\ncount    9031.000000\nmean       27.230429\nstd        46.197366\nmin         5.000000\n25%         7.000000\n50%        12.000000\n75%        26.000000\nmax       753.000000\ndtype: float64\n\n\n\n\n\n\n\n\n# 1. Importing Cartesian class from Package_Name\nfrom scripts.grid_3d import Cartesian\n\n# 2. Path to save the file\nplot_save_path = (\n    f\"{ASSETS_DIR}/cartesian_grid_with_residence_time.json\"\n)\n\n# 3. Performing analysis and generating plot\ncart = (\n    # Provide bin size for the 3D plot\n    Cartesian(bin_size=1.0)\n    # In case you are not sure about the extreme points\n    # .decide_boundaries(wind_data)\n    # Create grid points\n    .create_grid()\n    # Calculate residence time given wind satellite data\n    .add_residence_time(wind_data)\n    # Creating plot and saving as a json file (HPC save for big data)\n    .plot_3d(\n        variable=\"residence_time\",\n        path=plot_save_path,\n        show_earth=True,\n        show_sun=False,\n    )\n)\n\n# 4. Validation: Total time should be &gt; 0\ntotal_residence_time = cart.grid.residence_time.sum().item()\nprint(f\"Total residence time logged: {(total_residence_time):.1f} seconds\")\n\nUpdate in progress... processed 0 bins.\nUpdate in progress... processed 500 bins.\nUpdate in progress... processed 1000 bins.\nUpdate in progress... processed 1500 bins.\nGrid populated: 1547 bins updated.\nTotal residence time logged: 2988857.8 seconds\n\n\n\n\n\n\n\nimport plotly.io as pio\n\n# Reload and display the 3D Interactive Map\nif Path(plot_save_path).exists():\n    cartesian_fig = pio.read_json(str(plot_save_path))\n    cartesian_fig.show()\nelse:\n    print(f\"Error: Plot file not found at {plot_save_path}\")"
  },
  {
    "objectID": "index.html#project-environment-setup",
    "href": "index.html#project-environment-setup",
    "title": "AKR Map Visualisation from Wind Satellite Data",
    "section": "",
    "text": "# 1. Importing Libraries\nimport sys\nfrom pathlib import Path\n\n# 2. Setting project paths\nproject_root = Path.cwd()\nsys.path.append(str(project_root))\n\n# Define standard data subdirectories for easy access later\nRAW_DATA_DIR = project_root / \"data\" / \"raw\"\nPROCESSED_DATA_DIR = project_root / \"data\" / \"processed\"\nASSETS_DIR = project_root / \"assets\" / \"3D_Objects\""
  },
  {
    "objectID": "index.html#data-ingestion-pre-processing",
    "href": "index.html#data-ingestion-pre-processing",
    "title": "AKR Map Visualisation from Wind Satellite Data",
    "section": "",
    "text": "# 1. Importing functions from Package_Name\nfrom scripts.wind_data_reading import (\n    exploding_saving_wind_data,\n    load_apply_schema_wind_csv,\n)\n\n# 2. Loading and applying data type schema to wind data from CSV\nwind_data = load_apply_schema_wind_csv(\n    f\"{RAW_DATA_DIR}/fogg_akr_burst_list_1995_2004.csv\",\n)\n\n\n\n\n\n# 1. Exploding nested data and filtering NaNs\nwind_data_processed = exploding_saving_wind_data(wind_data)\n\nData cleaned. Remaining rows: 245918\n\n\n\n\n\n\n# 1. Processed data name\nprocessed_data_base_name = \"01_processed_wind_data_fogg_akr_burst_list_1995_2004\"\n\n# 2. Saving in parquet format (memory efficient)\nwind_data_processed.to_parquet(\n    f\"{PROCESSED_DATA_DIR}/{processed_data_base_name}.parquet\",\n    engine=\"pyarrow\",\n    index=False,\n)\n\n# 3. Saving in json format\nwind_data_processed.to_json(\n    f\"{PROCESSED_DATA_DIR}/{processed_data_base_name}.json\",\n    index=False,\n)\n\nprint(f\"Data successfully saved to: {PROCESSED_DATA_DIR}\")\n\nData successfully saved to: F:\\gitrepos\\AKR_3D_map\\data\\processed"
  },
  {
    "objectID": "index.html#importing-pre-processed-parquet-data-for-analysis",
    "href": "index.html#importing-pre-processed-parquet-data-for-analysis",
    "title": "AKR Map Visualisation from Wind Satellite Data",
    "section": "",
    "text": "# 1. Importing libraries\nimport pandas as pd\n\n# 2. Importing parquet file\nwind_data = pd.read_parquet(\n    f\"{project_root}/data/processed/01_processed_wind_data_fogg_akr_burst_list_1995_2004.parquet\",\n)\n\n# 3. Descriptory analysis\nprint(\"__________ Data type of columns __________\")\nprint(wind_data.dtypes)\nprint(\"\\n\")\nprint(\"__________ Data summary __________\")\nprint((wind_data.groupby(\"original_burst_id\").size().describe()))\n\n__________ Data type of columns __________\noriginal_burst_id             int64\nstime                datetime64[ns]\netime                datetime64[ns]\nburst_timestamp      datetime64[ns]\nmin_f_bound                 float64\nmax_f_bound                 float64\nLT_gse                      float64\nradius                      float64\nlat_gse                     float64\nlon_gse                     float64\nx_gse                       float64\ny_gse                       float64\nz_gse                       float64\ndtype: object\n\n\n__________ Data summary __________\ncount    9031.000000\nmean       27.230429\nstd        46.197366\nmin         5.000000\n25%         7.000000\n50%        12.000000\n75%        26.000000\nmax       753.000000\ndtype: float64"
  },
  {
    "objectID": "index.html#analysis-3d-grid-generation",
    "href": "index.html#analysis-3d-grid-generation",
    "title": "AKR Map Visualisation from Wind Satellite Data",
    "section": "",
    "text": "# 1. Importing Cartesian class from Package_Name\nfrom scripts.grid_3d import Cartesian\n\n# 2. Path to save the file\nplot_save_path = (\n    f\"{ASSETS_DIR}/cartesian_grid_with_residence_time.json\"\n)\n\n# 3. Performing analysis and generating plot\ncart = (\n    # Provide bin size for the 3D plot\n    Cartesian(bin_size=1.0)\n    # In case you are not sure about the extreme points\n    # .decide_boundaries(wind_data)\n    # Create grid points\n    .create_grid()\n    # Calculate residence time given wind satellite data\n    .add_residence_time(wind_data)\n    # Creating plot and saving as a json file (HPC save for big data)\n    .plot_3d(\n        variable=\"residence_time\",\n        path=plot_save_path,\n        show_earth=True,\n        show_sun=False,\n    )\n)\n\n# 4. Validation: Total time should be &gt; 0\ntotal_residence_time = cart.grid.residence_time.sum().item()\nprint(f\"Total residence time logged: {(total_residence_time):.1f} seconds\")\n\nUpdate in progress... processed 0 bins.\nUpdate in progress... processed 500 bins.\nUpdate in progress... processed 1000 bins.\nUpdate in progress... processed 1500 bins.\nGrid populated: 1547 bins updated.\nTotal residence time logged: 2988857.8 seconds"
  },
  {
    "objectID": "index.html#interactive-visualisation",
    "href": "index.html#interactive-visualisation",
    "title": "AKR Map Visualisation from Wind Satellite Data",
    "section": "",
    "text": "import plotly.io as pio\n\n# Reload and display the 3D Interactive Map\nif Path(plot_save_path).exists():\n    cartesian_fig = pio.read_json(str(plot_save_path))\n    cartesian_fig.show()\nelse:\n    print(f\"Error: Plot file not found at {plot_save_path}\")"
  }
]