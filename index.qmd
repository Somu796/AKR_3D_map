---
title: "AKR Map Visualisation from Wind Satellite Data"
author:
  - name: "Sudipta Kumar Hazra"
    affiliations:
      - name: "Dublin Institute for Advanced Studies (DIAS)"
        department: "School of Astrophysics"
  - name: "Alexandra Ruth Fogg"
    affiliations:
      - name: "Dublin Institute for Advanced Studies (DIAS)"
        department: "School of Astrophysics"
date: today
date-format: "MMMM D, YYYY"
number-sections: true
number-depth: 3
bibliography: references.bib
---
## Nitty-gritties
This study utilises archived observations of Auroral Kilometric Radiation (AKR) bursts, individually selected from the **Wind/WAVES** (1995–2004). The raw data were previously processed by @Fogg2022 to isolate distinct AKR emission clusters [(link to archive)](https://maser-lira.obspm.fr/publications/doi/bursts-of-auroral-kilometric-148.html).

The dataset consists of discrete AKR burst events. The following parameters are defined for each burst event:

- Temporal details: 
    - STIME : burst start in universal time (YYYY-MM-DDTHH:MM:SS.SSSSSSSSS)
    - ETIME : burst end in universal time (DD/MM/YYYY HH:MM:SS.SSSSSSSSS)
    - BURST_TIMESTAMP: list of universal times defining burst window, format YYYY-MM-DDTHH:MM:SS.SSSSSSSSS

- Spectral features:
    - MIN_F_BOUND: list of the lower frequency bound 
    - MAX_F_BOUND: list of the upper frequency bound 

- Coordiantes (at each BURST_TIMESTAMP):

    - Spehircal/local:
        - LT_GSE: list of spacecraft local times (hours)  
        - RADIUS: list of spacecraft radial distances (Earth radius)  
        - LAT_GSE: list of spacecraft latitude (degrees, in GSE coordinates)  

    - Cartesian (GSE): 
        - X_GSE: list of spacecraft position in X (Earth radii, in GSE coordinates)  
        - Y_GSE: list of spacecraft position in Y (Earth radii, GSE coordinates)  
    - Z_GSE: list of spacecraft position in Z (Earth radii, GSE coordinates)  

. Empty values are represented as “nan” or “NaT” depending to numeric (integer or float) or, datetime, respectively.  
. Frequency data and Coordinates as a function of BURST_TIMESTAMP.

## Objective:
The goal is to quantify AKR activity by mapping discrete satellite data into a 3D grid, focusing on four key variables:

(a) Observation Time: The cumulative duration spent actually detecting AKR in each bin (the sum of the burst windows),

(b) Normalised Observation Time: The ratio of observation time to residence time. This removes orbital bias to provide the true probability of AKR occurrence per location.

(c) Residence Time: The total time the Wind spacecraft spent in each bin. This measures the cumulative "exposure" time per location.

(d) Number of Bursts: The count of unique burst events in each bin, determined by the number of recorded burst start times (STIME).


## Project Environment Setup
```{python}
# 1. Importing Libraries
import sys
from pathlib import Path

# 2. Setting project paths
project_root = Path.cwd()
sys.path.append(str(project_root))

# Define standard data subdirectories for easy access later
RAW_DATA_DIR = project_root / "data" / "raw"
PROCESSED_DATA_DIR = project_root / "data" / "processed"
ASSETS_DIR = project_root / "assets" / "3D_Objects"

```

## Data Ingestion & Pre-processing
### *Reading* csv file and applying data type schema
```{python}
# | eval: false
# 1. Importing functions from Package_Name
from scripts.wind_data_reading import (
    exploding_saving_wind_data,
    load_apply_schema_wind_csv,
)

# 2. Loading and applying data type schema to wind data from CSV
wind_data = load_apply_schema_wind_csv(
    f"{RAW_DATA_DIR}/fogg_akr_burst_list_1995_2004.csv",
)
```

### *Processing:* Exploding the data and filtering
```{python}
# | eval: false
# 1. Exploding nested data and filtering NaNs
wind_data_processed = exploding_saving_wind_data(wind_data)
```

### *Saving* as parquet or json
```{python}
# | eval: false
# 1. Processed data name
processed_data_base_name = "01_processed_wind_data_fogg_akr_burst_list_1995_2004"

# 2. Saving in parquet format (memory efficient)
wind_data_processed.to_parquet(
    f"{PROCESSED_DATA_DIR}/{processed_data_base_name}.parquet",
    engine="pyarrow",
    index=False,
)

# 3. Saving in json format
wind_data_processed.to_json(
    f"{PROCESSED_DATA_DIR}/{processed_data_base_name}.json",
    index=False,
)

print(f"Data successfully saved to: {PROCESSED_DATA_DIR}")
```

## Importing Pre-processed Parquet Data for **Analysis**
```{python}
# 1. Importing libraries
import pandas as pd

# 2. Importing parquet file
wind_data = pd.read_parquet(
    f"{project_root}/data/processed/01_processed_wind_data_fogg_akr_burst_list_1995_2004.parquet",
)

# 3. Descriptory analysis
print("__________ Data type of columns __________")
display(wind_data.describe().T)
print("\n")
print("__________ Data summary __________")
display(wind_data.groupby("original_burst_id").size().describe().to_frame().T)
```

## Analysis & 3D Grid Generation

### Calculating residence time and preaping plot file 
```{python}
# 1. Importing Cartesian class from Package_Name
from scripts.grid_3d import Cartesian

# 2. Path to save the file
plot_save_path = f"{ASSETS_DIR}/cartesian_grid_with_observation_time.json"

# 3. Performing analysis and generating plot
cart = (
    # Provide bin size for the 3D plot
    Cartesian(bin_size=1.0)
    # In case you are not sure about the extreme points
    # .decide_boundaries(wind_data)
    # Create grid points
    .create_grid()
    # Calculate observations time given wind satellite data
    .add_observation_time(wind_data)
    # Creating plot and saving as a json file (HPC save for big data)
    .plot_3d(
        variable="observation_time",
        path=plot_save_path,
        show_earth=True,
        show_sun=False,
    )
)

# 4. Validation: Total time should be > 0
total_observation_time = cart.grid.observation_time.sum().item()
print(f"Total observations time logged: {(total_observation_time):.1f} seconds")
```

## Interactive Visualisation
```{python}
import plotly.io as pio

# Reload and display the 3D Interactive Map
if Path(plot_save_path).exists():
    cartesian_fig = pio.read_json(str(plot_save_path))
    cartesian_fig.show()
else:
    print(f"Error: Plot file not found at {plot_save_path}")
```
